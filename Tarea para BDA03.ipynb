{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plantilla para la Tarea online BDA03\n",
    "\n",
    "# Nombre del alumno: Juan González Andújar\n",
    "\n",
    "Realiza las tareas que se plantean en cada ejercicio. En algunas tareas deberás completar las celdas que están incompletas en otras añadir nuevas celdas. Se trata de que implementes una serie de consultas con HQL (Hive) y Pig Latin.\n",
    "\n",
    "Vamos a seguir utilizando el `dataset` de retrasos en vuelos en EEUU de la guía práctica. A modo de recordatorio, en el siguiente apartado, repetimos la explicación del significado de los campos.\n",
    "\n",
    "# Dataset de retrasos en vuelos\n",
    "\n",
    "Vamos a usar [este](https://www.kaggle.com/datasets/tylerx/flights-and-airports-data) de Kaggle\n",
    "para aprender a usar tanto Hive como Pig. Kaggle es un sitio muy popular en ciencia de datos. En este sitio los científicos de datos pueden publicar y compartir sus trabajos. Además también se pueden proponer concursos en los que los participantes compiten en la construcción del mejor modelo para el problema propuesto.\n",
    "\n",
    "El `dataset` contiene información sobre retrasos en vuelos en EEUU. Hay dos ficheros de interés: `airports.csv` y `flights.csv`.\n",
    "\n",
    "El primero tiene información sobre los aeropuertos y consta de los siguientes campos:\n",
    "   * airport_id: identificador del aeropuerto. Numérico, aunque se utilizará un campo `string` en Hive.\n",
    "   * city: ciudad del aeropuerto.\n",
    "   * state: estado del aeropuerto.\n",
    "   * name: nombre del aeropuerto.\n",
    "   \n",
    "El fichero `flights` tiene la siguiente estructura:\n",
    "   * DayofMonth: día del mes del vuelo.\n",
    "   * DayOfWeek: día de la semana del vuelo.\n",
    "   * Carrier: Identificador de la compañía aérea.\n",
    "   * OriginAirportID: Identificador del aeropuerto de origen.\n",
    "   * DestAirportID: Identificador del aeropuerto de destino.\n",
    "   * DepDelay: Minutos de retraso en la salida de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto).\n",
    "   * ArrDelay: Minutos de retraso en la llegada de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto).\n",
    "\n",
    "El directorio `notebooks` contiene el `archiv.zip` con los dos ficheros. Para descargarlo de Kaggle hay que estar registrado y se ha incluido para que no tengas que registrarte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Realiza el proceso de preparación que se hizo en la guia práctica:\n",
    "\n",
    "* Crea las celdas y muestra el resultado de su ejecución de la extracción de los ficheros del `dataset` de vuelos.\n",
    "* Crea la base de datos de Hive y las tablas `airports` y `flights`. Presta atención a cambiar los comentarios y no simplemente copiar los de la guía.\n",
    "* Carga las tablas y crea consultas de HQL que muestren 10 aeropuertos y 10 vuelos como se hizo en la guía práctica.\n",
    "* Crea un `script` en Pig Latin que muestre 10 aeropuertos y 10 vuelos como se hizo en la guía práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "DROP TABLE IF EXISTS airports: \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS flights (DayofMonth TINYINT, DayOfWeek Tinyint, Carrier STRING, \\\n",
    "OriginAirportID STRING, DestAirportID STRING, DepDelay INT, ArrDelay INT) \\\n",
    "COMMENT 'USA flights' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINNATED BY '\\,'\\\n",
    "TBLPROPERTIES ('Autor'='Juan Gonzalez','skip.header.line count'='1')\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 207 not upgraded.\n",
      "Need to get 168 kB of archives.\n",
      "After this operation, 593 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 unzip amd64 6.0-25ubuntu1.1 [168 kB]\n",
      "Fetched 168 kB in 1s (238 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 43749 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-25ubuntu1.1_amd64.deb ...\n",
      "Unpacking unzip (6.0-25ubuntu1.1) ...\n",
      "Setting up unzip (6.0-25ubuntu1.1) ...\n",
      "Processing triggers for mime-support (3.64ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "\n",
    "!apt-get install -y unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  archive.zip\n",
      "  inflating: airports.csv            \n",
      "  inflating: flights.csv             \n"
     ]
    }
   ],
   "source": [
    "!unzip -j -o archive.zip airports.csv flights.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 root supergroup      16308 2024-02-15 13:32 /user/root/flights/airports.csv\r\n",
      "-rw-r--r--   3 root supergroup   72088113 2024-02-15 13:32 /user/root/flights/flights.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mkdir -p /user/root/flights\n",
    "! hdfs dfs -put -f ./airports.csv /user/root/flights/\n",
    "! hdfs dfs -put -f ./flights.csv /user/root/flights/\n",
    "! hdfs dfs -ls /user/root/flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215132715_8827e6a3-1e09-4879-ba68-4013d5115be6): SHOW DATABASES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215132715_8827e6a3-1e09-4879-ba68-4013d5115be6); Time taken: 0.02 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215132715_8827e6a3-1e09-4879-ba68-4013d5115be6): SHOW DATABASES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215132715_8827e6a3-1e09-4879-ba68-4013d5115be6); Time taken: 0.032 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------+\n",
      "| database_name  |\n",
      "+----------------+\n",
      "| bda03          |\n",
      "| default        |\n",
      "+----------------+\n",
      "2 rows selected (0.158 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000\" -e \"SHOW DATABASES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215122942_9314d02a-0245-4730-a39c-943025700ba2): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos de la unidad BDA03' WITH DBPROPERTIES('Creada por '='Juan gonzalez')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215122942_9314d02a-0245-4730-a39c-943025700ba2); Time taken: 0.017 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215122942_9314d02a-0245-4730-a39c-943025700ba2): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos de la unidad BDA03' WITH DBPROPERTIES('Creada por '='Juan gonzalez')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215122942_9314d02a-0245-4730-a39c-943025700ba2); Time taken: 0.029 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.093 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000\" -e \"\\\n",
    "CREATE DATABASE IF NOT EXISTS bda03 \\\n",
    "COMMENT 'Base de datos de la unidad BDA03'\\\n",
    "WITH DBPROPERTIES('Creada por '='Juan gonzalez');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215132726_ba78c18a-edac-40be-9ace-519258f01246): DROP TABLE IF EXISTS airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215132726_ba78c18a-edac-40be-9ace-519258f01246); Time taken: 0.053 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215132726_ba78c18a-edac-40be-9ace-519258f01246): DROP TABLE IF EXISTS airports\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215132726_ba78c18a-edac-40be-9ace-519258f01246); Time taken: 0.306 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.418 seconds)\n",
      "INFO  : Compiling command(queryId=root_20240215132726_d40be5f5-86fe-4f17-9c4f-d8d92db17830): CREATE EXTERNAL TABLE IF NOT EXISTS airports (     airport_id STRING,     city STRING,     state STRING,     airportname STRING )  COMMENT 'USA Airports' ROW FORMAT DELIMITED  FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Author'='Juan Gonzalez','skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215132726_d40be5f5-86fe-4f17-9c4f-d8d92db17830); Time taken: 0.045 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215132726_d40be5f5-86fe-4f17-9c4f-d8d92db17830): CREATE EXTERNAL TABLE IF NOT EXISTS airports (     airport_id STRING,     city STRING,     state STRING,     airportname STRING )  COMMENT 'USA Airports' ROW FORMAT DELIMITED  FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Author'='Juan Gonzalez','skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215132726_d40be5f5-86fe-4f17-9c4f-d8d92db17830); Time taken: 0.06 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.121 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "DROP TABLE IF EXISTS airports; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS airports (\\\n",
    "    airport_id STRING,\\\n",
    "    city STRING,\\\n",
    "    state STRING,\\\n",
    "    airportname STRING\\\n",
    ") \\\n",
    "COMMENT 'USA Airports'\\\n",
    "ROW FORMAT DELIMITED \\\n",
    "FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Author'='Juan Gonzalez','skip.header.line.count'='1');\\\n",
    "\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215132735_12531034-a05e-49f8-bf49-fcf6913959fb): DROP TABLE IF EXISTS flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215132735_12531034-a05e-49f8-bf49-fcf6913959fb); Time taken: 0.046 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215132735_12531034-a05e-49f8-bf49-fcf6913959fb): DROP TABLE IF EXISTS flights\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215132735_12531034-a05e-49f8-bf49-fcf6913959fb); Time taken: 0.091 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.183 seconds)\n",
      "INFO  : Compiling command(queryId=root_20240215132735_672c8720-77d4-4b97-a39d-e7a0061f9bf0): CREATE EXTERNAL TABLE IF NOT EXISTS flights (DayofMonth TINYINT, DayOfWeek Tinyint, Carrier STRING,  OriginAirportID STRING, DestAirportID STRING, DepDelay SMALLINT, ArrDelay SMALLINT)  COMMENT 'USA flights'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' TBLPROPERTIES ('Author'='Juan Gonzalez','skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215132735_672c8720-77d4-4b97-a39d-e7a0061f9bf0); Time taken: 0.019 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215132735_672c8720-77d4-4b97-a39d-e7a0061f9bf0): CREATE EXTERNAL TABLE IF NOT EXISTS flights (DayofMonth TINYINT, DayOfWeek Tinyint, Carrier STRING,  OriginAirportID STRING, DestAirportID STRING, DepDelay SMALLINT, ArrDelay SMALLINT)  COMMENT 'USA flights'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' TBLPROPERTIES ('Author'='Juan Gonzalez','skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215132735_672c8720-77d4-4b97-a39d-e7a0061f9bf0); Time taken: 0.055 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.084 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "DROP TABLE IF EXISTS flights; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS flights (DayofMonth TINYINT, DayOfWeek Tinyint, Carrier STRING, \\\n",
    "OriginAirportID STRING, DestAirportID STRING, DepDelay SMALLINT, ArrDelay SMALLINT) \\\n",
    "COMMENT 'USA flights' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'\\\n",
    "TBLPROPERTIES ('Author'='Juan Gonzalez','skip.header.line.count'='1');\\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -chmod 777 /user/root/flights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215133341_2f164808-31b6-4ee0-bf9f-286233fd2b6e): LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215133341_2f164808-31b6-4ee0-bf9f-286233fd2b6e); Time taken: 0.052 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215133341_2f164808-31b6-4ee0-bf9f-286233fd2b6e): LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.airports from hdfs://namenode:8020/user/root/flights/airports.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215133341_2f164808-31b6-4ee0-bf9f-286233fd2b6e); Time taken: 0.481 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.583 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports;\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215133414_4fae7a17-960c-4a9c-8530-8d5baa62f0f9): LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215133414_4fae7a17-960c-4a9c-8530-8d5baa62f0f9); Time taken: 0.077 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215133414_4fae7a17-960c-4a9c-8530-8d5baa62f0f9): LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.flights from hdfs://namenode:8020/user/root/flights/flights.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240215133414_4fae7a17-960c-4a9c-8530-8d5baa62f0f9); Time taken: 0.408 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.55 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights;\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215133511_c322cc80-0603-4aef-b748-8971f53e4d66): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airports.airport_id, type:string, comment:null), FieldSchema(name:airports.city, type:string, comment:null), FieldSchema(name:airports.state, type:string, comment:null), FieldSchema(name:airports.airportname, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215133511_c322cc80-0603-4aef-b748-8971f53e4d66); Time taken: 1.46 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215133511_c322cc80-0603-4aef-b748-8971f53e4d66): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20240215133511_c322cc80-0603-4aef-b748-8971f53e4d66); Time taken: 0.001 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------------+----------------+-----------------+--------------------------------------+\n",
      "| airports.airport_id  | airports.city  | airports.state  |         airports.airportname         |\n",
      "+----------------------+----------------+-----------------+--------------------------------------+\n",
      "| 10165                | Adak Island    | AK              | Adak                                 |\n",
      "| 10299                | Anchorage      | AK              | Ted Stevens Anchorage International  |\n",
      "| 10304                | Aniak          | AK              | Aniak Airport                        |\n",
      "| 10754                | Barrow         | AK              | Wiley Post/Will Rogers Memorial      |\n",
      "| 10551                | Bethel         | AK              | Bethel Airport                       |\n",
      "| 10926                | Cordova        | AK              | Merle K Mudhole Smith                |\n",
      "| 14709                | Deadhorse      | AK              | Deadhorse Airport                    |\n",
      "| 11336                | Dillingham     | AK              | Dillingham Airport                   |\n",
      "| 11630                | Fairbanks      | AK              | Fairbanks International              |\n",
      "| 11997                | Gustavus       | AK              | Gustavus Airport                     |\n",
      "+----------------------+----------------+-----------------+--------------------------------------+\n",
      "10 rows selected (1.679 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT * FROM airports LIMIT 10 \\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215133611_9eec5608-e5e1-47e2-9491-6d19b60974ee): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:flights.dayofmonth, type:tinyint, comment:null), FieldSchema(name:flights.dayofweek, type:tinyint, comment:null), FieldSchema(name:flights.carrier, type:string, comment:null), FieldSchema(name:flights.originairportid, type:string, comment:null), FieldSchema(name:flights.destairportid, type:string, comment:null), FieldSchema(name:flights.depdelay, type:smallint, comment:null), FieldSchema(name:flights.arrdelay, type:smallint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215133611_9eec5608-e5e1-47e2-9491-6d19b60974ee); Time taken: 0.137 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215133611_9eec5608-e5e1-47e2-9491-6d19b60974ee): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20240215133611_9eec5608-e5e1-47e2-9491-6d19b60974ee); Time taken: 0.004 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+--------------------+------------------+--------------------------+------------------------+-------------------+-------------------+\n",
      "| flights.dayofmonth  | flights.dayofweek  | flights.carrier  | flights.originairportid  | flights.destairportid  | flights.depdelay  | flights.arrdelay  |\n",
      "+---------------------+--------------------+------------------+--------------------------+------------------------+-------------------+-------------------+\n",
      "| 19                  | 5                  | DL               | 11433                    | 13303                  | -3                | 1                 |\n",
      "| 19                  | 5                  | DL               | 14869                    | 12478                  | 0                 | -8                |\n",
      "| 19                  | 5                  | DL               | 14057                    | 14869                  | -4                | -15               |\n",
      "| 19                  | 5                  | DL               | 15016                    | 11433                  | 28                | 24                |\n",
      "| 19                  | 5                  | DL               | 11193                    | 12892                  | -6                | -11               |\n",
      "| 19                  | 5                  | DL               | 10397                    | 15016                  | -1                | -19               |\n",
      "| 19                  | 5                  | DL               | 15016                    | 10397                  | 0                 | -1                |\n",
      "| 19                  | 5                  | DL               | 10397                    | 14869                  | 15                | 24                |\n",
      "| 19                  | 5                  | DL               | 10397                    | 10423                  | 33                | 34                |\n",
      "| 19                  | 5                  | DL               | 11278                    | 10397                  | 323               | 322               |\n",
      "+---------------------+--------------------+------------------+--------------------------+------------------------+-------------------+-------------------+\n",
      "10 rows selected (0.328 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT * FROM flights LIMIT 10 \\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile flights.pig\n",
    "\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "AIRPORTS= LOAD '$airports_file' USING\n",
    "    org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE','UNIX','SKIP_INPUT_HEADER')\n",
    "    AS (airport_id:chararray,city:chararray,state:chararray,name:chararray);\n",
    "\n",
    "FLIGHTS= LOAD '$flights_file' USING\n",
    "org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE','UNIX','SKIP_INPUT_HEADER')\n",
    "AS (DayOfMonth:int,DayOfWeek:int,Carrier:chararray,OriginAirportID:chararray,DestAirportID:chararray,DepDelay:int,ArrDelay:int);\n",
    "\n",
    "Airports= LIMIT AIRPORTS 10;\n",
    "\n",
    "DUMP Airports;\n",
    "\n",
    "Flights= LIMIT FLIGHTS 10;\n",
    "\n",
    "DUMP Flights;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 16:31:20,370 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-02-15 16:31:20,370 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-02-15 16:31:20,441 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-02-15 16:31:20,441 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/BDA3/notebooks/pig_1708011080436.log\n",
      "2024-02-15 16:31:20,463 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-02-15 16:31:20,617 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-02-15 16:31:20,689 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 16:31:20,691 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-02-15 16:31:20,718 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-flights.pig-3102c8f0-2b5a-4527-a561-3ec66e7bf193\n",
      "2024-02-15 16:31:20,718 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-02-15 16:31:21,339 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2024-02-15 16:31:21,397 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-15 16:31:21,489 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 16:31:21,555 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 16:31:21,555 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 16:31:21,629 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 16:31:21,634 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 16:31:21,637 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 16:31:21,687 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp1997932666/tmp946122693\n",
      "2024-02-15 16:31:21,695 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 16:31:21,701 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 16:31:21,701 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(10165,Adak Island,AK,Adak)\n",
      "(10299,Anchorage,AK,Ted Stevens Anchorage International)\n",
      "(10304,Aniak,AK,Aniak Airport)\n",
      "(10754,Barrow,AK,Wiley Post/Will Rogers Memorial)\n",
      "(10551,Bethel,AK,Bethel Airport)\n",
      "(10926,Cordova,AK,Merle K Mudhole Smith)\n",
      "(14709,Deadhorse,AK,Deadhorse Airport)\n",
      "(11336,Dillingham,AK,Dillingham Airport)\n",
      "(11630,Fairbanks,AK,Fairbanks International)\n",
      "(11997,Gustavus,AK,Gustavus Airport)\n",
      "2024-02-15 16:31:21,750 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2024-02-15 16:31:21,763 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 16:31:21,764 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-15 16:31:21,793 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 16:31:21,794 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 16:31:21,814 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 16:31:21,819 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 16:31:21,819 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 16:31:21,826 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp1997932666/tmp-210257241\n",
      "2024-02-15 16:31:21,829 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 16:31:21,833 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 16:31:21,833 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(19,5,DL,11433,13303,-3,1)\n",
      "(19,5,DL,14869,12478,0,-8)\n",
      "(19,5,DL,14057,14869,-4,-15)\n",
      "(19,5,DL,15016,11433,28,24)\n",
      "(19,5,DL,11193,12892,-6,-11)\n",
      "(19,5,DL,10397,15016,-1,-19)\n",
      "(19,5,DL,15016,10397,0,-1)\n",
      "(19,5,DL,10397,14869,15,24)\n",
      "(19,5,DL,10397,10423,33,34)\n",
      "(19,5,DL,11278,10397,323,322)\n",
      "2024-02-15 16:31:21,888 [main] INFO  org.apache.pig.Main - Pig script completed in 1 second and 746 milliseconds (1746 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Con una consulta de HQL muestra: La cinco compañías que más vuelos retrasados tienen.\n",
    "\n",
    "* El campo `carrier` contiene la compañía aérea.\n",
    "* Vamos a considerar que un vuelo llega con retraso cuando el vuelo llega más de 15 minutos tarde (campo `arrdelay` > 15).\n",
    "\n",
    "Se espera el siguiente resultado:\n",
    "\n",
    "![solución 2](./img/2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215164318_3aca42eb-0a48-4218-838e-2f096056f66f): SELECT Carrier, COUNT(*) AS delayed_flights  FROM flights WHERE arrdelay>15  GROUP BY Carrier ORDER BY delayed_flights DESC  LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:carrier, type:string, comment:null), FieldSchema(name:delayed_flights, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215164318_3aca42eb-0a48-4218-838e-2f096056f66f); Time taken: 0.229 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215164318_3aca42eb-0a48-4218-838e-2f096056f66f): SELECT Carrier, COUNT(*) AS delayed_flights  FROM flights WHERE arrdelay>15  GROUP BY Carrier ORDER BY delayed_flights DESC  LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20240215164318_3aca42eb-0a48-4218-838e-2f096056f66f\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1708009121782_0003\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1708009121782_0003/\n",
      "INFO  : Starting Job = job_1708009121782_0003, Tracking URL = http://yarnmaster:8088/proxy/application_1708009121782_0003/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1708009121782_0003\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-15 16:43:26,979 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-15 16:43:35,237 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.25 sec\n",
      "INFO  : 2024-02-15 16:43:41,453 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 7.97 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 7 seconds 970 msec\n",
      "INFO  : Ended Job = job_1708009121782_0003\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1708009121782_0004\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1708009121782_0004/\n",
      "INFO  : Starting Job = job_1708009121782_0004, Tracking URL = http://yarnmaster:8088/proxy/application_1708009121782_0004/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1708009121782_0004\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-15 16:43:50,517 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-15 16:43:56,680 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.06 sec\n",
      "INFO  : 2024-02-15 16:44:02,925 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.66 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 660 msec\n",
      "INFO  : Ended Job = job_1708009121782_0004\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 7.97 sec   HDFS Read: 72103104 HDFS Write: 465 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.66 sec   HDFS Read: 8081 HDFS Write: 193 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 12 seconds 630 msec\n",
      "INFO  : Completed executing command(queryId=root_20240215164318_3aca42eb-0a48-4218-838e-2f096056f66f); Time taken: 45.054 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------+------------------+\n",
      "| carrier  | delayed_flights  |\n",
      "+----------+------------------+\n",
      "| WN       | 127601           |\n",
      "| AA       | 59842            |\n",
      "| DL       | 57668            |\n",
      "| UA       | 57367            |\n",
      "| US       | 40943            |\n",
      "+----------+------------------+\n",
      "5 rows selected (45.363 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT Carrier, COUNT(*) AS delayed_flights \\\n",
    "FROM flights WHERE arrdelay>15 \\\n",
    "GROUP BY Carrier\\\n",
    "ORDER BY delayed_flights DESC \\\n",
    "LIMIT 5 \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Con una consulta de HQL muestra: Las 5 compañías que mejor recuperación de tiempo en vuelo tienen.\n",
    "\n",
    "* Se considera que se ha recuperado el tiempo de un vuelo cuando habiendo salido con retraso (`depdelay` > 15), llega sin retraso (`arraydelay` <= 15).\n",
    "* Se trata de que muestres las 5 compañías que han recuperado el tiempo en un mayor porcentaje de vuelos que salieron retrasados.\n",
    "\n",
    "El resultado esperado es el siguiente:\n",
    "\n",
    "![solución 3](./img/3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240215172258_b6edf262-c049-4653-a23f-c41e856d1903): SELECT Carrier,         ROUND(SUM(CASE WHEN DepDelay > 15 AND ArrDelay <= 15 THEN 1 ELSE 0 END) /  COUNT(*) ,17) AS percent_recovered  FROM flights  WHERE DepDelay > 15  GROUP BY Carrier  ORDER BY percent_recovered DESC  LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:carrier, type:string, comment:null), FieldSchema(name:percent_recovered, type:double, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240215172258_b6edf262-c049-4653-a23f-c41e856d1903); Time taken: 0.217 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240215172258_b6edf262-c049-4653-a23f-c41e856d1903): SELECT Carrier,         ROUND(SUM(CASE WHEN DepDelay > 15 AND ArrDelay <= 15 THEN 1 ELSE 0 END) /  COUNT(*) ,17) AS percent_recovered  FROM flights  WHERE DepDelay > 15  GROUP BY Carrier  ORDER BY percent_recovered DESC  LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20240215172258_b6edf262-c049-4653-a23f-c41e856d1903\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1708009121782_0013\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1708009121782_0013/\n",
      "INFO  : Starting Job = job_1708009121782_0013, Tracking URL = http://yarnmaster:8088/proxy/application_1708009121782_0013/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1708009121782_0013\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-15 17:23:05,697 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-15 17:23:13,938 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.5 sec\n",
      "INFO  : 2024-02-15 17:23:21,182 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 9.37 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 9 seconds 370 msec\n",
      "INFO  : Ended Job = job_1708009121782_0013\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1708009121782_0014\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1708009121782_0014/\n",
      "INFO  : Starting Job = job_1708009121782_0014, Tracking URL = http://yarnmaster:8088/proxy/application_1708009121782_0014/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1708009121782_0014\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-15 17:23:28,925 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-15 17:23:35,103 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.89 sec\n",
      "INFO  : 2024-02-15 17:23:41,296 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.27 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 270 msec\n",
      "INFO  : Ended Job = job_1708009121782_0014\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 9.37 sec   HDFS Read: 72105897 HDFS Write: 544 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.27 sec   HDFS Read: 8037 HDFS Write: 261 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 13 seconds 640 msec\n",
      "INFO  : Completed executing command(queryId=root_20240215172258_b6edf262-c049-4653-a23f-c41e856d1903); Time taken: 43.283 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------+----------------------+\n",
      "| carrier  |  percent_recovered   |\n",
      "+----------+----------------------+\n",
      "| UA       | 0.24507301133462678  |\n",
      "| WN       | 0.23570878543927196  |\n",
      "| FL       | 0.2265728843597696   |\n",
      "| DL       | 0.21578780710414067  |\n",
      "| AA       | 0.20162014676224854  |\n",
      "+----------+----------------------+\n",
      "5 rows selected (43.573 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT Carrier, \\\n",
    "       ROUND(SUM(CASE WHEN DepDelay > 15 AND ArrDelay <= 15 THEN 1 ELSE 0 END) / \\\n",
    "COUNT(*) ,17) AS percent_recovered \\\n",
    "FROM flights \\\n",
    "WHERE DepDelay > 15 \\\n",
    "GROUP BY Carrier \\\n",
    "ORDER BY percent_recovered DESC \\\n",
    "LIMIT 5;\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Resuelve el ejercicio 2 con Pig Latin\n",
    "\n",
    "El resultado esperado es:\n",
    "\n",
    "![solución 4](./img/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile flights.pig\n",
    "\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "-- Carga de datos de los vuelos\n",
    "FLIGHTS = LOAD '$flights_file' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE','UNIX','SKIP_INPUT_HEADER') AS (DayOfMonth:int, DayOfWeek:int, Carrier:chararray, OriginAirportID:chararray, DestAirportID:chararray, DepDelay:int, ArrDelay:int);\n",
    "\n",
    "-- Filtrar vuelos retrasados\n",
    "delayed_flights = FILTER FLIGHTS BY DepDelay > 15;\n",
    "\n",
    "-- Contar vuelos retrasados por compañía\n",
    "grouped_flights = GROUP delayed_flights BY Carrier;\n",
    "flight_count = FOREACH grouped_flights GENERATE group AS Carrier, COUNT(delayed_flights) AS delayed_count;\n",
    "\n",
    "-- Ordenar por número de vuelos retrasados en orden descendente\n",
    "sorted_flights = ORDER flight_count BY delayed_count DESC;\n",
    "\n",
    "-- Mostrar las cinco compañías con más vuelos retrasados\n",
    "top_5_carriers = LIMIT sorted_flights 5;\n",
    "\n",
    "-- Mostrar resultados\n",
    "DUMP top_5_carriers;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 17:36:21,732 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-02-15 17:36:21,733 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-02-15 17:36:21,808 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-02-15 17:36:21,808 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/BDA3/notebooks/pig_1708014981804.log\n",
      "2024-02-15 17:36:21,837 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-02-15 17:36:22,051 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-02-15 17:36:22,115 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 17:36:22,118 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-02-15 17:36:22,144 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-flights.pig-3c33a3c7-2011-4eb5-849f-8941cd1538f5\n",
      "2024-02-15 17:36:22,144 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-02-15 17:36:22,851 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "2024-02-15 17:36:22,890 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-15 17:36:22,966 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:23,021 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2024-02-15 17:36:23,044 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-02-15 17:36:23,067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-43\n",
      "2024-02-15 17:36:23,077 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 4\n",
      "2024-02-15 17:36:23,077 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 4\n",
      "2024-02-15 17:36:23,187 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsConfig - Loaded properties from hadoop-metrics2.properties\n",
      "2024-02-15 17:36:23,323 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-02-15 17:36:23,323 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started\n",
      "2024-02-15 17:36:23,341 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 17:36:23,346 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 17:36:23,346 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 17:36:23,348 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2024-02-15 17:36:23,350 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 17:36:23,351 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-15 17:36:23,356 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=72088113\n",
      "2024-02-15 17:36:23,357 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 17:36:23,357 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 17:36:23,369 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 17:36:23,378 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2024-02-15 17:36:23,378 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2024-02-15 17:36:23,378 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1708014983378-0\n",
      "2024-02-15 17:36:23,472 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 17:36:23,479 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:23,492 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2024-02-15 17:36:23,548 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 17:36:23,574 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 17:36:23,574 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 17:36:23,605 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n",
      "2024-02-15 17:36:23,681 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3\n",
      "2024-02-15 17:36:23,829 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local571981759_0001\n",
      "2024-02-15 17:36:23,829 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 17:36:24,058 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 17:36:24,058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local571981759_0001\n",
      "2024-02-15 17:36:24,058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases FLIGHTS,delayed_flights,flight_count,grouped_flights\n",
      "2024-02-15 17:36:24,058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: FLIGHTS[5,10],FLIGHTS[-1,-1],delayed_flights[8,18],flight_count[12,15],grouped_flights[11,18] C: flight_count[12,15],grouped_flights[11,18] R: flight_count[12,15]\n",
      "2024-02-15 17:36:24,061 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 17:36:24,069 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2024-02-15 17:36:24,069 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local571981759_0001]\n",
      "2024-02-15 17:36:24,100 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 17:36:24,101 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 17:36:24,101 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 17:36:24,108 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:24,109 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:24,110 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 17:36:24,165 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 17:36:24,166 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local571981759_0001_m_000000_0\n",
      "2024-02-15 17:36:24,223 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:24,223 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:24,255 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:24,268 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 17:36:24,286 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/BDA3/notebooks/flights.csv:0+33554432\n",
      "2024-02-15 17:36:24,352 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 17:36:24,352 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 17:36:24,352 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 17:36:24,352 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 17:36:24,352 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 17:36:24,356 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 17:36:24,368 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:24,370 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2024-02-15 17:36:24,388 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[5,10],FLIGHTS[-1,-1],delayed_flights[8,18],flight_count[12,15],grouped_flights[11,18] C: flight_count[12,15],grouped_flights[11,18] R: flight_count[12,15]\n",
      "2024-02-15 17:36:28,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 17:36:28,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 17:36:28,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 17:36:28,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2639030; bufvoid = 104857600\n",
      "2024-02-15 17:36:28,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25158788(100635152); length = 1055609/6553600\n",
      "2024-02-15 17:36:28,592 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[5,10],FLIGHTS[-1,-1],delayed_flights[8,18],flight_count[12,15],grouped_flights[11,18] C: flight_count[12,15],grouped_flights[11,18] R: flight_count[12,15]\n",
      "2024-02-15 17:36:28,895 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 17:36:28,912 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local571981759_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:28,915 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 17:36:28,915 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local571981759_0001_m_000000_0' done.\n",
      "2024-02-15 17:36:28,927 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local571981759_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33559756\n",
      "\t\tFILE: Number of bytes written=629326\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=263903\n",
      "\t\tMap output bytes=2639030\n",
      "\t\tMap output materialized bytes=232\n",
      "\t\tInput split bytes=375\n",
      "\t\tCombine input records=263903\n",
      "\t\tCombine output records=16\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=41\n",
      "\t\tTotal committed heap usage (bytes)=499646464\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 17:36:28,927 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local571981759_0001_m_000000_0\n",
      "2024-02-15 17:36:28,928 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local571981759_0001_m_000001_0\n",
      "2024-02-15 17:36:28,939 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:28,939 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:28,940 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:28,942 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 17:36:28,947 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/BDA3/notebooks/flights.csv:33554432+33554432\n",
      "2024-02-15 17:36:28,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 17:36:28,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 17:36:28,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 17:36:28,964 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 17:36:28,964 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 17:36:28,965 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 17:36:28,970 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:28,971 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:28,978 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[5,10],FLIGHTS[-1,-1],delayed_flights[8,18],flight_count[12,15],grouped_flights[11,18] C: flight_count[12,15],grouped_flights[11,18] R: flight_count[12,15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 17:36:29,080 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 12% complete\n",
      "2024-02-15 17:36:29,084 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local571981759_0001]\n",
      "2024-02-15 17:36:33,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 17:36:33,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 17:36:33,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 17:36:33,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2360410; bufvoid = 104857600\n",
      "2024-02-15 17:36:33,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25270236(101080944); length = 944161/6553600\n",
      "2024-02-15 17:36:33,242 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 17:36:33,244 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local571981759_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:33,246 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 17:36:33,246 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local571981759_0001_m_000001_0' done.\n",
      "2024-02-15 17:36:33,246 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local571981759_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67119436\n",
      "\t\tFILE: Number of bytes written=629590\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=236041\n",
      "\t\tMap output bytes=2360410\n",
      "\t\tMap output materialized bytes=232\n",
      "\t\tInput split bytes=375\n",
      "\t\tCombine input records=236041\n",
      "\t\tCombine output records=16\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=237\n",
      "\t\tTotal committed heap usage (bytes)=612368384\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 17:36:33,247 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local571981759_0001_m_000001_0\n",
      "2024-02-15 17:36:33,247 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local571981759_0001_m_000002_0\n",
      "2024-02-15 17:36:33,255 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:33,255 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:33,256 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:33,259 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 17:36:33,266 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/BDA3/notebooks/flights.csv:67108864+4979249\n",
      "2024-02-15 17:36:33,283 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 17:36:33,283 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 17:36:33,284 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 17:36:33,284 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 17:36:33,284 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 17:36:33,285 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 17:36:33,290 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:33,290 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:33,295 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[5,10],FLIGHTS[-1,-1],delayed_flights[8,18],flight_count[12,15],grouped_flights[11,18] C: flight_count[12,15],grouped_flights[11,18] R: flight_count[12,15]\n",
      "2024-02-15 17:36:34,007 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 17:36:34,007 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 17:36:34,007 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 17:36:34,007 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 232760; bufvoid = 104857600\n",
      "2024-02-15 17:36:34,007 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26121296(104485184); length = 93101/6553600\n",
      "2024-02-15 17:36:34,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 17:36:34,047 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local571981759_0001_m_000002_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:34,048 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 17:36:34,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local571981759_0001_m_000002_0' done.\n",
      "2024-02-15 17:36:34,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local571981759_0001_m_000002_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72099325\n",
      "\t\tFILE: Number of bytes written=629795\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=23276\n",
      "\t\tMap output bytes=232760\n",
      "\t\tMap output materialized bytes=173\n",
      "\t\tInput split bytes=375\n",
      "\t\tCombine input records=23276\n",
      "\t\tCombine output records=12\n",
      "\t\tSpilled Records=12\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=214\n",
      "\t\tTotal committed heap usage (bytes)=664797184\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 17:36:34,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local571981759_0001_m_000002_0\n",
      "2024-02-15 17:36:34,049 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 17:36:34,055 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 17:36:34,056 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local571981759_0001_r_000000_0\n",
      "2024-02-15 17:36:34,081 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:34,081 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:34,085 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:34,090 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6df7c2e7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 17:36:34,092 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,119 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 17:36:34,123 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local571981759_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 17:36:34,157 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local571981759_0001_m_000000_0 decomp: 228 len: 232 to MEMORY\n",
      "2024-02-15 17:36:34,160 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 228 bytes from map-output for attempt_local571981759_0001_m_000000_0\n",
      "2024-02-15 17:36:34,162 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 228, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->228\n",
      "2024-02-15 17:36:34,164 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local571981759_0001_m_000002_0 decomp: 169 len: 173 to MEMORY\n",
      "2024-02-15 17:36:34,164 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 169 bytes from map-output for attempt_local571981759_0001_m_000002_0\n",
      "2024-02-15 17:36:34,164 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 169, inMemoryMapOutputs.size() -> 2, commitMemory -> 228, usedMemory ->397\n",
      "2024-02-15 17:36:34,165 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local571981759_0001_m_000001_0 decomp: 228 len: 232 to MEMORY\n",
      "2024-02-15 17:36:34,166 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 228 bytes from map-output for attempt_local571981759_0001_m_000001_0\n",
      "2024-02-15 17:36:34,166 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 228, inMemoryMapOutputs.size() -> 3, commitMemory -> 397, usedMemory ->625\n",
      "2024-02-15 17:36:34,166 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 17:36:34,169 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-15 17:36:34,169 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 17:36:34,177 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 3 sorted segments\n",
      "2024-02-15 17:36:34,177 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 604 bytes\n",
      "2024-02-15 17:36:34,179 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 625 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 17:36:34,180 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 625 bytes from disk\n",
      "2024-02-15 17:36:34,181 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 17:36:34,181 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 17:36:34,181 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 614 bytes\n",
      "2024-02-15 17:36:34,182 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-15 17:36:34,190 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:34,190 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:34,194 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-02-15 17:36:34,194 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:34,195 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:34,199 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[5,10],FLIGHTS[-1,-1],delayed_flights[8,18],flight_count[12,15],grouped_flights[11,18] C: flight_count[12,15],grouped_flights[11,18] R: flight_count[12,15]\n",
      "2024-02-15 17:36:34,205 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local571981759_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:34,211 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-15 17:36:34,211 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local571981759_0001_r_000000_0 is allowed to commit now\n",
      "2024-02-15 17:36:34,216 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local571981759_0001_r_000000_0' to file:/tmp/temp730396522/tmp1329414297\n",
      "2024-02-15 17:36:34,217 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 17:36:34,217 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local571981759_0001_r_000000_0' done.\n",
      "2024-02-15 17:36:34,218 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local571981759_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72100683\n",
      "\t\tFILE: Number of bytes written=630634\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=16\n",
      "\t\tReduce shuffle bytes=637\n",
      "\t\tReduce input records=44\n",
      "\t\tReduce output records=16\n",
      "\t\tSpilled Records=44\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=664797184\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 17:36:34,218 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local571981759_0001_r_000000_0\n",
      "2024-02-15 17:36:34,219 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-15 17:36:34,379 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 25% complete\n",
      "2024-02-15 17:36:34,382 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,394 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,395 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2024-02-15 17:36:34,396 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,434 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 17:36:34,437 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 17:36:34,438 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 17:36:34,438 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-15 17:36:34,439 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=202\n",
      "2024-02-15 17:36:34,441 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 17:36:34,444 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 17:36:34,487 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 17:36:34,489 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,495 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 17:36:34,502 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 17:36:34,502 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 17:36:34,502 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 17:36:34,506 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-15 17:36:34,531 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local652190478_0002\n",
      "2024-02-15 17:36:34,531 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 17:36:34,645 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 17:36:34,646 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 17:36:34,653 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 17:36:34,653 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 17:36:34,653 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 17:36:34,653 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:34,653 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:34,654 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 17:36:34,661 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 17:36:34,661 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local652190478_0002_m_000000_0\n",
      "2024-02-15 17:36:34,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:34,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:34,672 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:34,674 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 202\n",
      "Input split[0]:\n",
      "   Length = 202\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 17:36:34,680 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp730396522/tmp1329414297/part-r-00000:0+202\n",
      "2024-02-15 17:36:34,693 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 17:36:34,694 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 17:36:34,694 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 17:36:34,694 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 17:36:34,694 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 17:36:34,697 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 17:36:34,701 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:34,701 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:34,703 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[15,17] C:  R: \n",
      "2024-02-15 17:36:34,705 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 17:36:34,705 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 17:36:34,705 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 17:36:34,705 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 308; bufvoid = 104857600\n",
      "2024-02-15 17:36:34,705 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-15 17:36:34,707 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 17:36:34,709 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local652190478_0002_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:34,710 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 17:36:34,710 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local652190478_0002_m_000000_0' done.\n",
      "2024-02-15 17:36:34,711 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local652190478_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72101333\n",
      "\t\tFILE: Number of bytes written=1243007\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=308\n",
      "\t\tMap output materialized bytes=346\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=665321472\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 17:36:34,711 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local652190478_0002_m_000000_0\n",
      "2024-02-15 17:36:34,711 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 17:36:34,712 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 17:36:34,712 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local652190478_0002_r_000000_0\n",
      "2024-02-15 17:36:34,730 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:34,731 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:34,736 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:34,737 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@11609c5c\n",
      "2024-02-15 17:36:34,737 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,738 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 17:36:34,738 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local652190478_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 17:36:34,740 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local652190478_0002_m_000000_0 decomp: 342 len: 346 to MEMORY\n",
      "2024-02-15 17:36:34,740 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 342 bytes from map-output for attempt_local652190478_0002_m_000000_0\n",
      "2024-02-15 17:36:34,741 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 342, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->342\n",
      "2024-02-15 17:36:34,741 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 17:36:34,742 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 17:36:34,742 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 17:36:34,743 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 17:36:34,743 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 326 bytes\n",
      "2024-02-15 17:36:34,744 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 342 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 17:36:34,744 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 346 bytes from disk\n",
      "2024-02-15 17:36:34,744 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 17:36:34,744 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 17:36:34,745 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 326 bytes\n",
      "2024-02-15 17:36:34,745 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 17:36:34,748 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:34,748 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:34,750 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:34,750 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:34,755 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[15,17] C:  R: \n",
      "2024-02-15 17:36:34,761 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local652190478_0002_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:34,767 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 17:36:34,767 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local652190478_0002_r_000000_0 is allowed to commit now\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 17:36:34,775 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local652190478_0002_r_000000_0' to file:/tmp/temp730396522/tmp-1002275179\n",
      "2024-02-15 17:36:34,779 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 17:36:34,779 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local652190478_0002_r_000000_0' done.\n",
      "2024-02-15 17:36:34,782 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local652190478_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102057\n",
      "\t\tFILE: Number of bytes written=1243416\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=346\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=16\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=665321472\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 17:36:34,782 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local652190478_0002_r_000000_0\n",
      "2024-02-15 17:36:34,783 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-15 17:36:34,946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local652190478_0002\n",
      "2024-02-15 17:36:34,946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted_flights\n",
      "2024-02-15 17:36:34,946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted_flights[15,17] C:  R: \n",
      "2024-02-15 17:36:34,947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n",
      "2024-02-15 17:36:34,949 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,950 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,951 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,954 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 17:36:34,954 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 17:36:34,955 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 17:36:34,955 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 17:36:34,957 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 17:36:34,977 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 17:36:34,980 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:34,987 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 17:36:34,991 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 17:36:34,991 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 17:36:34,991 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-15 17:36:34,994 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-15 17:36:35,019 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local705917703_0003\n",
      "2024-02-15 17:36:35,019 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 17:36:35,106 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 17:36:35,107 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 17:36:35,113 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 17:36:35,113 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 17:36:35,113 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 17:36:35,113 [Thread-24] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:35,113 [Thread-24] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:35,114 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 17:36:35,122 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 17:36:35,122 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local705917703_0003_m_000000_0\n",
      "2024-02-15 17:36:35,130 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:35,130 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:35,131 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:35,133 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 202\n",
      "Input split[0]:\n",
      "   Length = 202\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 17:36:35,137 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp730396522/tmp1329414297/part-r-00000:0+202\n",
      "2024-02-15 17:36:35,159 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 17:36:35,159 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 17:36:35,159 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 17:36:35,159 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 17:36:35,159 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 17:36:35,161 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 17:36:35,166 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:35,166 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:35,168 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[15,17] C:  R: \n",
      "2024-02-15 17:36:35,170 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 17:36:35,170 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 17:36:35,170 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 17:36:35,170 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288; bufvoid = 104857600\n",
      "2024-02-15 17:36:35,170 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-15 17:36:35,185 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 17:36:35,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local705917703_0003_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:35,190 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 17:36:35,190 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local705917703_0003_m_000000_0' done.\n",
      "2024-02-15 17:36:35,190 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local705917703_0003_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102707\n",
      "\t\tFILE: Number of bytes written=1862126\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=288\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=16\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=665321472\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 17:36:35,190 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local705917703_0003_m_000000_0\n",
      "2024-02-15 17:36:35,190 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 17:36:35,196 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 17:36:35,197 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local705917703_0003_r_000000_0\n",
      "2024-02-15 17:36:35,214 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:35,215 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:35,221 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:35,221 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15d2be8d\n",
      "2024-02-15 17:36:35,221 [pool-12-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,223 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 17:36:35,228 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local705917703_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 17:36:35,229 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local705917703_0003_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-02-15 17:36:35,230 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local705917703_0003_m_000000_0\n",
      "2024-02-15 17:36:35,230 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-02-15 17:36:35,230 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 17:36:35,231 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 17:36:35,231 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 17:36:35,236 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 17:36:35,236 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-15 17:36:35,238 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 17:36:35,238 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-02-15 17:36:35,238 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 17:36:35,238 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 17:36:35,239 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-15 17:36:35,239 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 17:36:35,243 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:35,243 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:35,244 [pool-12-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:35,245 [pool-12-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:35,248 [pool-12-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[15,17] C:  R: \n",
      "2024-02-15 17:36:35,255 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local705917703_0003_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:35,261 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 17:36:35,261 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local705917703_0003_r_000000_0 is allowed to commit now\n",
      "2024-02-15 17:36:35,270 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local705917703_0003_r_000000_0' to file:/tmp/temp730396522/tmp-1795487588\n",
      "2024-02-15 17:36:35,272 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 17:36:35,272 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local705917703_0003_r_000000_0' done.\n",
      "2024-02-15 17:36:35,272 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local705917703_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102951\n",
      "\t\tFILE: Number of bytes written=1862314\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=665321472\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 17:36:35,272 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local705917703_0003_r_000000_0\n",
      "2024-02-15 17:36:35,273 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-15 17:36:35,407 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local705917703_0003\n",
      "2024-02-15 17:36:35,407 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted_flights\n",
      "2024-02-15 17:36:35,407 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted_flights[15,17] C:  R: \n",
      "2024-02-15 17:36:35,409 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 75% complete\n",
      "2024-02-15 17:36:35,411 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,412 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,413 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,417 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-15 17:36:35,417 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-15 17:36:35,418 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-15 17:36:35,418 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-15 17:36:35,421 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-15 17:36:35,432 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-15 17:36:35,435 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,442 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-15 17:36:35,445 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 17:36:35,445 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-15 17:36:35,445 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 17:36:35,447 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-15 17:36:35,470 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local528838396_0004\n",
      "2024-02-15 17:36:35,470 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-15 17:36:35,546 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-15 17:36:35,546 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-15 17:36:35,553 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-15 17:36:35,554 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-15 17:36:35,554 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-15 17:36:35,554 [Thread-31] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:35,554 [Thread-31] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:35,554 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-15 17:36:35,559 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-15 17:36:35,559 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local528838396_0004_m_000000_0\n",
      "2024-02-15 17:36:35,567 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:35,567 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:35,568 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:35,570 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 70\n",
      "Input split[0]:\n",
      "   Length = 70\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-15 17:36:35,572 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp730396522/tmp-1795487588/part-r-00000:0+70\n",
      "2024-02-15 17:36:35,584 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-15 17:36:35,584 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-15 17:36:35,584 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-15 17:36:35,584 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-15 17:36:35,584 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-15 17:36:35,585 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-15 17:36:35,587 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:35,587 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:35,588 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[15,17] C:  R: \n",
      "2024-02-15 17:36:35,588 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-15 17:36:35,588 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-15 17:36:35,588 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-15 17:36:35,588 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 90; bufvoid = 104857600\n",
      "2024-02-15 17:36:35,588 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2024-02-15 17:36:35,590 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-15 17:36:35,592 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local528838396_0004_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:35,593 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-15 17:36:35,593 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local528838396_0004_m_000000_0' done.\n",
      "2024-02-15 17:36:35,594 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local528838396_0004_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103469\n",
      "\t\tFILE: Number of bytes written=2468563\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=90\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=665321472\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-15 17:36:35,594 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local528838396_0004_m_000000_0\n",
      "2024-02-15 17:36:35,594 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-15 17:36:35,594 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-15 17:36:35,595 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local528838396_0004_r_000000_0\n",
      "2024-02-15 17:36:35,609 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:35,609 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:35,612 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-15 17:36:35,612 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@39d1c6ec\n",
      "2024-02-15 17:36:35,612 [pool-15-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,614 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-15 17:36:35,615 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local528838396_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-15 17:36:35,617 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local528838396_0004_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-02-15 17:36:35,621 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local528838396_0004_m_000000_0\n",
      "2024-02-15 17:36:35,621 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-02-15 17:36:35,622 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-15 17:36:35,623 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 17:36:35,623 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-15 17:36:35,625 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 17:36:35,626 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-15 17:36:35,626 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-15 17:36:35,627 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-02-15 17:36:35,627 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-15 17:36:35,627 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-15 17:36:35,627 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-15 17:36:35,628 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 17:36:35,631 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-15 17:36:35,631 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-15 17:36:35,634 [pool-15-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-15 17:36:35,634 [pool-15-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:35,637 [pool-15-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[15,17] C:  R: \n",
      "2024-02-15 17:36:35,638 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local528838396_0004_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-15 17:36:35,641 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-15 17:36:35,641 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local528838396_0004_r_000000_0 is allowed to commit now\n",
      "2024-02-15 17:36:35,644 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local528838396_0004_r_000000_0' to file:/tmp/temp730396522/tmp-2138631556\n",
      "2024-02-15 17:36:35,644 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-15 17:36:35,644 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local528838396_0004_r_000000_0' done.\n",
      "2024-02-15 17:36:35,645 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local528838396_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103713\n",
      "\t\tFILE: Number of bytes written=2468751\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=665321472\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-15 17:36:35,645 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local528838396_0004_r_000000_0\n",
      "2024-02-15 17:36:35,645 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 17:36:35,847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local528838396_0004\n",
      "2024-02-15 17:36:35,847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted_flights\n",
      "2024-02-15 17:36:35,847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted_flights[15,17] C:  R: \n",
      "2024-02-15 17:36:35,850 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,852 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,854 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2024-02-15 17:36:35,871 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.3.1\t0.17.0\troot\t2024-02-15 17:36:23\t2024-02-15 17:36:35\tGROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local528838396_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted_flights\t\tfile:/tmp/temp730396522/tmp-2138631556,\n",
      "job_local571981759_0001\t3\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tFLIGHTS,delayed_flights,flight_count,grouped_flights\tGROUP_BY,COMBINER\t\n",
      "job_local652190478_0002\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted_flights\tSAMPLER\t\n",
      "job_local705917703_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted_flights\tORDER_BY,COMBINER\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/BDA3/notebooks/flights.csv\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 5 records in: \"file:/tmp/temp730396522/tmp-2138631556\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 5\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local571981759_0001\t->\tjob_local652190478_0002,\n",
      "job_local652190478_0002\t->\tjob_local705917703_0003,\n",
      "job_local705917703_0003\t->\tjob_local528838396_0004,\n",
      "job_local528838396_0004\n",
      "\n",
      "\n",
      "2024-02-15 17:36:35,872 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,874 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,876 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,884 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,886 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,887 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,891 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,893 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,895 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,899 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,901 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,902 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-15 17:36:35,905 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2024-02-15 17:36:35,910 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-15 17:36:35,913 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-15 17:36:35,913 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(WN,142850)\n",
      "(AA,59007)\n",
      "(UA,58758)\n",
      "(DL,53687)\n",
      "(EV,36161)\n",
      "2024-02-15 17:36:35,964 [main] INFO  org.apache.pig.Main - Pig script completed in 14 seconds and 491 milliseconds (14491 ms)\n"
     ]
    }
   ],
   "source": [
    "!pig -x local -f flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Resuelve el ejercicio 3 con Pig Latin\n",
    "\n",
    "Se espera el siguiente resultado:\n",
    "\n",
    "![solución 5](./img/5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile flights.pig\n",
    "-- Carga de datos desde el archivo flights.csv utilizando PigStorage\n",
    "REGISTER piggybank.jar\n",
    "flights= LOAD '$flights_file' USING\n",
    "org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE','UNIX','SKIP_INPUT_HEADER')\n",
    "AS (DayOfMonth:int,DayOfWeek:int,Carrier:chararray,OriginAirportID:chararray,DestAirportID:chararray,DepDelay:int,ArrDelay:int);\n",
    "\n",
    "-- Filtrado de vuelos con salida retrasada (DepDelay > 15)\n",
    "delayed_flights = FILTER flights BY DepDelay > 15;\n",
    "\n",
    "-- Filtrado de vuelos recuperados (ArrDelay <= 15)\n",
    "recovered_flights = FILTER delayed_flights BY ArrDelay <= 15;\n",
    "\n",
    "-- Agrupación por compañía y cálculo del número de vuelos recuperados por compañía\n",
    "grouped_recovery_count = GROUP recovered_flights BY Carrier;\n",
    "recovery_count = FOREACH grouped_recovery_count GENERATE group AS Carrier, COUNT(recovered_flights) AS recovered_count;\n",
    "\n",
    "-- Agrupación por compañía y cálculo del número total de vuelos con salida retrasada por compañía\n",
    "grouped_total_count = GROUP delayed_flights BY Carrier;\n",
    "total_count = FOREACH grouped_total_count GENERATE group AS Carrier, COUNT(delayed_flights) AS total_count;\n",
    "\n",
    "-- Unión de las tablas de vuelos totales con retraso y vuelos recuperados por compañía\n",
    "merged_data = JOIN recovery_count BY Carrier, total_count BY Carrier;\n",
    "\n",
    "-- Cálculo del porcentaje de vuelos recuperados\n",
    "percent_recovered = FOREACH merged_data GENERATE recovery_count::Carrier AS Carrier, (double)recovery_count::recovered_count / (double)total_count::total_count AS percent_recovered;\n",
    "\n",
    "-- Ordenar porcentaje de vuelos recuperados en orden descendente\n",
    "sorted_data = ORDER percent_recovered BY percent_recovered DESC;\n",
    "\n",
    "-- Limitar los resultados a los primeros 5\n",
    "top_5_carriers = LIMIT sorted_data 5;\n",
    "\n",
    "-- Mostrar resultados\n",
    "DUMP top_5_carriers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:42,630 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-02-16 08:28:42,630 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-02-16 08:28:42,699 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-02-16 08:28:42,699 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/BDA3/notebooks/pig_1708068522695.log\n",
      "2024-02-16 08:28:42,719 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-02-16 08:28:42,898 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-02-16 08:28:42,970 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-16 08:28:42,973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-02-16 08:28:43,009 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-flights.pig-d3b5e03c-85a4-4439-be42-0dd6aaece67b\n",
      "2024-02-16 08:28:43,010 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-02-16 08:28:43,823 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "2024-02-16 08:28:43,900 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-16 08:28:43,985 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:44,047 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2024-02-16 08:28:44,069 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-02-16 08:28:44,077 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-02-16 08:28:44,089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-96\n",
      "2024-02-16 08:28:44,093 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer - Rewrite: POPackage->POForEach to POPackage(JoinPackager)\n",
      "2024-02-16 08:28:44,100 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 7\n",
      "2024-02-16 08:28:44,102 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged MR job 83 into MR job 80\n",
      "2024-02-16 08:28:44,102 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged MR job 88 into MR job 80\n",
      "2024-02-16 08:28:44,102 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Requested parallelism of splitter: -1\n",
      "2024-02-16 08:28:44,102 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 2 map-reduce splittees.\n",
      "2024-02-16 08:28:44,102 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 2 out of total 3 MR operators.\n",
      "2024-02-16 08:28:44,102 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 5\n",
      "2024-02-16 08:28:44,272 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsConfig - Loaded properties from hadoop-metrics2.properties\n",
      "2024-02-16 08:28:44,366 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-02-16 08:28:44,366 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started\n",
      "2024-02-16 08:28:44,393 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-16 08:28:44,399 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-16 08:28:44,399 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-16 08:28:44,401 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2024-02-16 08:28:44,404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-16 08:28:44,405 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-16 08:28:44,411 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=72088113\n",
      "2024-02-16 08:28:44,411 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-16 08:28:44,411 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-16 08:28:44,421 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up multi store job\n",
      "2024-02-16 08:28:44,433 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2024-02-16 08:28:44,433 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2024-02-16 08:28:44,433 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1708068524433-0\n",
      "2024-02-16 08:28:44,547 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-16 08:28:44,556 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:44,570 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2024-02-16 08:28:44,636 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-16 08:28:44,654 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-16 08:28:44,654 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-16 08:28:44,671 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n",
      "2024-02-16 08:28:44,728 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3\n",
      "2024-02-16 08:28:44,901 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1000492054_0001\n",
      "2024-02-16 08:28:44,901 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-16 08:28:45,092 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-16 08:28:45,094 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1000492054_0001\n",
      "2024-02-16 08:28:45,094 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases delayed_flights,flights,grouped_recovery_count,grouped_total_count,recovered_flights,recovery_count,total_count\n",
      "2024-02-16 08:28:45,094 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: flights[3,9],flights[-1,-1],delayed_flights[8,18],recovered_flights[11,20],recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] C: recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] R: recovery_count[15,17],total_count[19,14]\n",
      "2024-02-16 08:28:45,095 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-16 08:28:45,107 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2024-02-16 08:28:45,107 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1000492054_0001]\n",
      "2024-02-16 08:28:45,129 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-16 08:28:45,130 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-16 08:28:45,130 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-16 08:28:45,133 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:45,133 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:45,136 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:45,136 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:45,136 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:45,196 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-16 08:28:45,196 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1000492054_0001_m_000000_0\n",
      "2024-02-16 08:28:45,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:45,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:45,252 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:45,252 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:45,273 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:45,280 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-16 08:28:45,298 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/BDA3/notebooks/flights.csv:0+33554432\n",
      "2024-02-16 08:28:45,369 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-16 08:28:45,369 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-16 08:28:45,370 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-16 08:28:45,370 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-16 08:28:45,370 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-16 08:28:45,376 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-16 08:28:45,395 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:45,397 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2024-02-16 08:28:45,422 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: flights[3,9],flights[-1,-1],delayed_flights[8,18],recovered_flights[11,20],recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] C: recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] R: recovery_count[15,17],total_count[19,14]\n",
      "2024-02-16 08:28:49,494 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-16 08:28:49,495 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-16 08:28:49,495 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-16 08:28:49,495 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 3119320; bufvoid = 104857600\n",
      "2024-02-16 08:28:49,495 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24966672(99866688); length = 1247725/6553600\n",
      "2024-02-16 08:28:49,644 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: flights[3,9],flights[-1,-1],delayed_flights[8,18],recovered_flights[11,20],recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] C: recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] R: recovery_count[15,17],total_count[19,14]\n",
      "2024-02-16 08:28:49,944 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-16 08:28:49,957 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1000492054_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:49,959 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-16 08:28:49,959 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1000492054_0001_m_000000_0' done.\n",
      "2024-02-16 08:28:49,969 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1000492054_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33559756\n",
      "\t\tFILE: Number of bytes written=642091\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=311932\n",
      "\t\tMap output bytes=3119320\n",
      "\t\tMap output materialized bytes=455\n",
      "\t\tInput split bytes=375\n",
      "\t\tCombine input records=311932\n",
      "\t\tCombine output records=32\n",
      "\t\tSpilled Records=32\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=48\n",
      "\t\tTotal committed heap usage (bytes)=499122176\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-16 08:28:49,969 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1000492054_0001_m_000000_0\n",
      "2024-02-16 08:28:49,970 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1000492054_0001_m_000001_0\n",
      "2024-02-16 08:28:49,975 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:49,976 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:49,979 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:49,979 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:49,979 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:49,981 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-16 08:28:49,986 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/BDA3/notebooks/flights.csv:33554432+33554432\n",
      "2024-02-16 08:28:50,001 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-16 08:28:50,001 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-16 08:28:50,001 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-16 08:28:50,001 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-16 08:28:50,001 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-16 08:28:50,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-16 08:28:50,008 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:50,009 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:50,018 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: flights[3,9],flights[-1,-1],delayed_flights[8,18],recovered_flights[11,20],recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] C: recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] R: recovery_count[15,17],total_count[19,14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:50,119 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 10% complete\n",
      "2024-02-16 08:28:50,119 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1000492054_0001]\n",
      "2024-02-16 08:28:53,852 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-16 08:28:53,852 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-16 08:28:53,852 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-16 08:28:53,852 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2854600; bufvoid = 104857600\n",
      "2024-02-16 08:28:53,852 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25072560(100290240); length = 1141837/6553600\n",
      "2024-02-16 08:28:54,135 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-16 08:28:54,137 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1000492054_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:54,138 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-16 08:28:54,138 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1000492054_0001_m_000001_0' done.\n",
      "2024-02-16 08:28:54,139 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1000492054_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67119436\n",
      "\t\tFILE: Number of bytes written=642578\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=285460\n",
      "\t\tMap output bytes=2854600\n",
      "\t\tMap output materialized bytes=455\n",
      "\t\tInput split bytes=375\n",
      "\t\tCombine input records=285460\n",
      "\t\tCombine output records=32\n",
      "\t\tSpilled Records=32\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=242\n",
      "\t\tTotal committed heap usage (bytes)=611319808\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-16 08:28:54,139 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1000492054_0001_m_000001_0\n",
      "2024-02-16 08:28:54,139 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1000492054_0001_m_000002_0\n",
      "2024-02-16 08:28:54,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:54,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:54,145 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:54,145 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:54,146 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:54,148 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-16 08:28:54,152 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/BDA3/notebooks/flights.csv:67108864+4979249\n",
      "2024-02-16 08:28:54,164 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-16 08:28:54,165 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-16 08:28:54,165 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-16 08:28:54,166 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-16 08:28:54,166 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-16 08:28:54,166 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-16 08:28:54,171 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:54,171 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:54,179 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: flights[3,9],flights[-1,-1],delayed_flights[8,18],recovered_flights[11,20],recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] C: recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] R: recovery_count[15,17],total_count[19,14]\n",
      "2024-02-16 08:28:54,847 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-16 08:28:54,847 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-16 08:28:54,847 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-16 08:28:54,847 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288340; bufvoid = 104857600\n",
      "2024-02-16 08:28:54,847 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26099064(104396256); length = 115333/6553600\n",
      "2024-02-16 08:28:54,872 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-16 08:28:54,874 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1000492054_0001_m_000002_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:54,875 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-16 08:28:54,875 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1000492054_0001_m_000002_0' done.\n",
      "2024-02-16 08:28:54,876 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1000492054_0001_m_000002_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72099325\n",
      "\t\tFILE: Number of bytes written=642949\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=28834\n",
      "\t\tMap output bytes=288340\n",
      "\t\tMap output materialized bytes=339\n",
      "\t\tInput split bytes=375\n",
      "\t\tCombine input records=28834\n",
      "\t\tCombine output records=24\n",
      "\t\tSpilled Records=24\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=198\n",
      "\t\tTotal committed heap usage (bytes)=660078592\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-16 08:28:54,876 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1000492054_0001_m_000002_0\n",
      "2024-02-16 08:28:54,876 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-16 08:28:54,879 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-16 08:28:54,879 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1000492054_0001_r_000000_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:54,898 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:54,898 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:54,901 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:54,901 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:54,905 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:54,907 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3370165e\n",
      "2024-02-16 08:28:54,909 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:54,924 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-16 08:28:54,926 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1000492054_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-16 08:28:54,953 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1000492054_0001_m_000001_0 decomp: 451 len: 455 to MEMORY\n",
      "2024-02-16 08:28:54,956 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 451 bytes from map-output for attempt_local1000492054_0001_m_000001_0\n",
      "2024-02-16 08:28:54,957 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->451\n",
      "2024-02-16 08:28:54,959 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1000492054_0001_m_000002_0 decomp: 335 len: 339 to MEMORY\n",
      "2024-02-16 08:28:54,960 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 335 bytes from map-output for attempt_local1000492054_0001_m_000002_0\n",
      "2024-02-16 08:28:54,960 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 335, inMemoryMapOutputs.size() -> 2, commitMemory -> 451, usedMemory ->786\n",
      "2024-02-16 08:28:54,961 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1000492054_0001_m_000000_0 decomp: 451 len: 455 to MEMORY\n",
      "2024-02-16 08:28:54,961 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 451 bytes from map-output for attempt_local1000492054_0001_m_000000_0\n",
      "2024-02-16 08:28:54,962 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 451, inMemoryMapOutputs.size() -> 3, commitMemory -> 786, usedMemory ->1237\n",
      "2024-02-16 08:28:54,962 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-16 08:28:54,962 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-16 08:28:54,963 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-16 08:28:54,969 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 3 sorted segments\n",
      "2024-02-16 08:28:54,969 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 1216 bytes\n",
      "2024-02-16 08:28:54,970 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 1237 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-16 08:28:54,971 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1237 bytes from disk\n",
      "2024-02-16 08:28:54,972 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-16 08:28:54,972 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-16 08:28:54,972 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1226 bytes\n",
      "2024-02-16 08:28:54,973 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-16 08:28:54,976 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-02-16 08:28:54,977 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:54,977 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:54,980 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: flights[3,9],flights[-1,-1],delayed_flights[8,18],recovered_flights[11,20],recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] C: recovery_count[15,17],grouped_recovery_count[14,25],total_count[19,14],grouped_total_count[18,22] R: recovery_count[15,17],total_count[19,14]\n",
      "2024-02-16 08:28:54,986 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:54,986 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:54,993 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:54,993 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:55,001 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1000492054_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:55,010 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-16 08:28:55,010 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1000492054_0001_r_000000_0 is allowed to commit now\n",
      "2024-02-16 08:28:55,015 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1000492054_0001_r_000000_0' to file:/tmp/temp-328978134/tmp2062180404\n",
      "2024-02-16 08:28:55,018 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1000492054_0001_r_000000_0' to file:/tmp/temp-328978134/tmp-226797878\n",
      "2024-02-16 08:28:55,019 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-16 08:28:55,019 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1000492054_0001_r_000000_0' done.\n",
      "2024-02-16 08:28:55,019 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1000492054_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72101907\n",
      "\t\tFILE: Number of bytes written=644606\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=32\n",
      "\t\tReduce shuffle bytes=1249\n",
      "\t\tReduce input records=88\n",
      "\t\tReduce output records=0\n",
      "\t\tSpilled Records=88\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=660078592\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-16 08:28:55,019 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1000492054_0001_r_000000_0\n",
      "2024-02-16 08:28:55,019 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:55,166 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 20% complete\n",
      "2024-02-16 08:28:55,169 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:55,179 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:55,180 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2024-02-16 08:28:55,181 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:55,209 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-16 08:28:55,209 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-16 08:28:55,210 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-16 08:28:55,210 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-16 08:28:55,213 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=396\n",
      "2024-02-16 08:28:55,213 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-16 08:28:55,215 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-16 08:28:55,238 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-16 08:28:55,240 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:55,247 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-16 08:28:55,254 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-16 08:28:55,254 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-16 08:28:55,255 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-16 08:28:55,257 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-16 08:28:55,257 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-16 08:28:55,257 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-16 08:28:55,261 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2024-02-16 08:28:55,274 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local760497629_0002\n",
      "2024-02-16 08:28:55,274 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-16 08:28:55,380 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-16 08:28:55,381 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-16 08:28:55,395 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-16 08:28:55,396 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-16 08:28:55,396 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-16 08:28:55,396 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:55,396 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:55,397 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-16 08:28:55,410 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-16 08:28:55,410 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local760497629_0002_m_000000_0\n",
      "2024-02-16 08:28:55,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:55,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:55,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:55,420 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 202\n",
      "Input split[0]:\n",
      "   Length = 202\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-16 08:28:55,424 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-328978134/tmp-226797878/part-r-00000:0+202\n",
      "2024-02-16 08:28:55,441 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-16 08:28:55,442 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-16 08:28:55,443 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-16 08:28:55,443 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-16 08:28:55,443 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-16 08:28:55,443 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-16 08:28:55,450 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:55,451 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:55,452 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: merged_data[22,14],merged_data[22,14] C:  R: percent_recovered[25,20]\n",
      "2024-02-16 08:28:55,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-16 08:28:55,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-16 08:28:55,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-16 08:28:55,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 186; bufvoid = 104857600\n",
      "2024-02-16 08:28:55,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-16 08:28:55,458 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-16 08:28:55,460 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local760497629_0002_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:55,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-16 08:28:55,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local760497629_0002_m_000000_0' done.\n",
      "2024-02-16 08:28:55,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local760497629_0002_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102956\n",
      "\t\tFILE: Number of bytes written=1256770\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=186\n",
      "\t\tMap output materialized bytes=224\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=7\n",
      "\t\tTotal committed heap usage (bytes)=661127168\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _1_tmp-226797878=16\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-16 08:28:55,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local760497629_0002_m_000000_0\n",
      "2024-02-16 08:28:55,462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local760497629_0002_m_000001_0\n",
      "2024-02-16 08:28:55,468 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:55,468 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:55,469 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:55,470 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 194\n",
      "Input split[0]:\n",
      "   Length = 194\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-16 08:28:55,475 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-328978134/tmp2062180404/part-r-00000:0+194\n",
      "2024-02-16 08:28:55,490 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-16 08:28:55,490 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-16 08:28:55,491 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-16 08:28:55,491 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-16 08:28:55,491 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-16 08:28:55,492 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:55,495 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:55,495 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:55,496 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: merged_data[22,14],merged_data[22,14] C:  R: percent_recovered[25,20]\n",
      "2024-02-16 08:28:55,498 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-16 08:28:55,498 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-16 08:28:55,498 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-16 08:28:55,498 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 178; bufvoid = 104857600\n",
      "2024-02-16 08:28:55,498 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-16 08:28:55,500 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-16 08:28:55,504 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local760497629_0002_m_000001_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:55,506 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-16 08:28:55,506 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local760497629_0002_m_000001_0' done.\n",
      "2024-02-16 08:28:55,506 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local760497629_0002_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103945\n",
      "\t\tFILE: Number of bytes written=1257018\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=178\n",
      "\t\tMap output materialized bytes=216\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=661127168\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _0_tmp2062180404=16\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-16 08:28:55,506 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local760497629_0002_m_000001_0\n",
      "2024-02-16 08:28:55,507 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-16 08:28:55,508 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-16 08:28:55,513 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local760497629_0002_r_000000_0\n",
      "2024-02-16 08:28:55,530 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:55,530 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:55,533 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:55,533 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2201c6f7\n",
      "2024-02-16 08:28:55,533 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:55,534 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-16 08:28:55,534 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local760497629_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-16 08:28:55,537 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local760497629_0002_m_000000_0 decomp: 220 len: 224 to MEMORY\n",
      "2024-02-16 08:28:55,538 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 220 bytes from map-output for attempt_local760497629_0002_m_000000_0\n",
      "2024-02-16 08:28:55,538 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->220\n",
      "2024-02-16 08:28:55,540 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local760497629_0002_m_000001_0 decomp: 212 len: 216 to MEMORY\n",
      "2024-02-16 08:28:55,541 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 212 bytes from map-output for attempt_local760497629_0002_m_000001_0\n",
      "2024-02-16 08:28:55,541 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 212, inMemoryMapOutputs.size() -> 2, commitMemory -> 220, usedMemory ->432\n",
      "2024-02-16 08:28:55,542 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-16 08:28:55,542 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-02-16 08:28:55,543 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-16 08:28:55,544 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 2 sorted segments\n",
      "2024-02-16 08:28:55,545 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 418 bytes\n",
      "2024-02-16 08:28:55,546 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 432 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-16 08:28:55,546 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 434 bytes from disk\n",
      "2024-02-16 08:28:55,547 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-16 08:28:55,547 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-16 08:28:55,548 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 423 bytes\n",
      "2024-02-16 08:28:55,549 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-02-16 08:28:55,556 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:55,556 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:55,557 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:55,558 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:55,561 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: merged_data[22,14],merged_data[22,14] C:  R: percent_recovered[25,20]\n",
      "2024-02-16 08:28:55,573 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local760497629_0002_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:55,577 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-02-16 08:28:55,577 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local760497629_0002_r_000000_0 is allowed to commit now\n",
      "2024-02-16 08:28:55,581 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local760497629_0002_r_000000_0' to file:/tmp/temp-328978134/tmp-1939487191\n",
      "2024-02-16 08:28:55,582 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-16 08:28:55,582 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local760497629_0002_r_000000_0' done.\n",
      "2024-02-16 08:28:55,582 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local760497629_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72104883\n",
      "\t\tFILE: Number of bytes written=1257752\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=16\n",
      "\t\tReduce shuffle bytes=440\n",
      "\t\tReduce input records=32\n",
      "\t\tReduce output records=16\n",
      "\t\tSpilled Records=32\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=661127168\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-16 08:28:55,583 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local760497629_0002_r_000000_0\n",
      "2024-02-16 08:28:55,583 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:55,739 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local760497629_0002\n",
      "2024-02-16 08:28:55,739 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases merged_data,percent_recovered\n",
      "2024-02-16 08:28:55,739 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: merged_data[22,14],merged_data[22,14] C:  R: percent_recovered[25,20]\n",
      "2024-02-16 08:28:55,740 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 40% complete\n",
      "2024-02-16 08:28:55,741 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:55,743 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:55,744 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:55,748 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-16 08:28:55,749 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-16 08:28:55,750 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-16 08:28:55,750 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-16 08:28:55,751 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=288\n",
      "2024-02-16 08:28:55,752 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-16 08:28:55,754 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-16 08:28:55,775 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-16 08:28:55,777 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:55,781 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-16 08:28:55,784 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-16 08:28:55,784 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-16 08:28:55,784 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-16 08:28:55,786 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-16 08:28:55,801 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1441971638_0003\n",
      "2024-02-16 08:28:55,801 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-16 08:28:55,899 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-16 08:28:55,900 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-16 08:28:55,909 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-16 08:28:55,909 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-16 08:28:55,909 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-16 08:28:55,910 [Thread-25] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:55,910 [Thread-25] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:55,910 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-16 08:28:55,922 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-16 08:28:55,922 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1441971638_0003_m_000000_0\n",
      "2024-02-16 08:28:55,930 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:55,930 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:55,931 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:55,932 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 288\n",
      "Input split[0]:\n",
      "   Length = 288\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-16 08:28:55,935 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-328978134/tmp-1939487191/part-r-00000:0+288\n",
      "2024-02-16 08:28:55,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-16 08:28:55,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-16 08:28:55,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-16 08:28:55,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-16 08:28:55,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-16 08:28:55,971 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-16 08:28:55,974 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:55,975 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:55,977 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_data[28,14] C:  R: \n",
      "2024-02-16 08:28:55,981 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-16 08:28:55,981 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-16 08:28:55,981 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-16 08:28:55,981 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 480; bufvoid = 104857600\n",
      "2024-02-16 08:28:55,981 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-16 08:28:55,983 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-16 08:28:55,993 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1441971638_0003_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:55,994 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-16 08:28:55,994 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1441971638_0003_m_000000_0' done.\n",
      "2024-02-16 08:28:55,994 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1441971638_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72105622\n",
      "\t\tFILE: Number of bytes written=1873940\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=480\n",
      "\t\tMap output materialized bytes=518\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=10\n",
      "\t\tTotal committed heap usage (bytes)=660078592\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-16 08:28:55,995 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1441971638_0003_m_000000_0\n",
      "2024-02-16 08:28:55,995 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-16 08:28:55,996 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-16 08:28:55,996 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1441971638_0003_r_000000_0\n",
      "2024-02-16 08:28:56,009 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,009 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,012 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:56,012 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6365b191\n",
      "2024-02-16 08:28:56,013 [pool-12-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:56,018 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-16 08:28:56,020 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1441971638_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-16 08:28:56,023 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1441971638_0003_m_000000_0 decomp: 514 len: 518 to MEMORY\n",
      "2024-02-16 08:28:56,023 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 514 bytes from map-output for attempt_local1441971638_0003_m_000000_0\n",
      "2024-02-16 08:28:56,024 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 514, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->514\n",
      "2024-02-16 08:28:56,024 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-16 08:28:56,025 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-16 08:28:56,025 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-16 08:28:56,027 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-16 08:28:56,027 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 494 bytes\n",
      "2024-02-16 08:28:56,027 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 514 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-16 08:28:56,028 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 518 bytes from disk\n",
      "2024-02-16 08:28:56,028 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-16 08:28:56,028 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-16 08:28:56,028 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 494 bytes\n",
      "2024-02-16 08:28:56,028 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-16 08:28:56,030 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,030 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,032 [pool-12-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:56,032 [pool-12-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:56,036 [pool-12-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_data[28,14] C:  R: \n",
      "2024-02-16 08:28:56,039 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1441971638_0003_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:56,042 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-16 08:28:56,043 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1441971638_0003_r_000000_0 is allowed to commit now\n",
      "2024-02-16 08:28:56,046 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1441971638_0003_r_000000_0' to file:/tmp/temp-328978134/tmp1480035431\n",
      "2024-02-16 08:28:56,047 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-16 08:28:56,047 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1441971638_0003_r_000000_0' done.\n",
      "2024-02-16 08:28:56,047 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1441971638_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72106690\n",
      "\t\tFILE: Number of bytes written=1874527\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=518\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=16\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=660078592\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-16 08:28:56,048 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1441971638_0003_r_000000_0\n",
      "2024-02-16 08:28:56,048 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-16 08:28:56,205 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1441971638_0003\n",
      "2024-02-16 08:28:56,205 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted_data\n",
      "2024-02-16 08:28:56,205 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted_data[28,14] C:  R: \n",
      "2024-02-16 08:28:56,206 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 60% complete\n",
      "2024-02-16 08:28:56,207 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,208 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,209 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,212 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-16 08:28:56,212 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-16 08:28:56,213 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-16 08:28:56,213 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-16 08:28:56,215 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-16 08:28:56,236 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-16 08:28:56,238 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,244 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-16 08:28:56,247 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-16 08:28:56,247 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-16 08:28:56,247 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-16 08:28:56,250 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-16 08:28:56,262 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1341026145_0004\n",
      "2024-02-16 08:28:56,262 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:56,330 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-16 08:28:56,330 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-16 08:28:56,335 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-16 08:28:56,335 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-16 08:28:56,335 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-16 08:28:56,335 [Thread-32] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,335 [Thread-32] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,336 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-16 08:28:56,339 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-16 08:28:56,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1341026145_0004_m_000000_0\n",
      "2024-02-16 08:28:56,345 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,345 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,345 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:56,347 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 288\n",
      "Input split[0]:\n",
      "   Length = 288\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-16 08:28:56,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-328978134/tmp-1939487191/part-r-00000:0+288\n",
      "2024-02-16 08:28:56,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-16 08:28:56,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-16 08:28:56,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-16 08:28:56,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-16 08:28:56,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-16 08:28:56,359 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-16 08:28:56,362 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:56,362 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:56,364 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_data[28,14] C:  R: \n",
      "2024-02-16 08:28:56,365 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-16 08:28:56,365 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-16 08:28:56,365 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-16 08:28:56,365 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288; bufvoid = 104857600\n",
      "2024-02-16 08:28:56,365 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-16 08:28:56,377 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-16 08:28:56,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1341026145_0004_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:56,382 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-16 08:28:56,382 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1341026145_0004_m_000000_0' done.\n",
      "2024-02-16 08:28:56,385 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1341026145_0004_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107429\n",
      "\t\tFILE: Number of bytes written=2496914\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=288\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=16\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=660078592\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-16 08:28:56,385 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1341026145_0004_m_000000_0\n",
      "2024-02-16 08:28:56,385 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-16 08:28:56,387 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-16 08:28:56,387 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1341026145_0004_r_000000_0\n",
      "2024-02-16 08:28:56,394 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,394 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,395 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:56,395 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3b9777a3\n",
      "2024-02-16 08:28:56,396 [pool-15-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,397 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-16 08:28:56,398 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1341026145_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-16 08:28:56,399 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local1341026145_0004_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-02-16 08:28:56,401 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local1341026145_0004_m_000000_0\n",
      "2024-02-16 08:28:56,401 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-02-16 08:28:56,402 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-16 08:28:56,403 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-16 08:28:56,403 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-16 08:28:56,404 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-16 08:28:56,404 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-16 08:28:56,405 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-16 08:28:56,406 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-02-16 08:28:56,406 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-16 08:28:56,406 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-16 08:28:56,406 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-16 08:28:56,406 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-16 08:28:56,408 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,408 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,409 [pool-15-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:56,409 [pool-15-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:56,411 [pool-15-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_data[28,14] C:  R: \n",
      "2024-02-16 08:28:56,412 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1341026145_0004_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:56,416 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-16 08:28:56,416 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1341026145_0004_r_000000_0 is allowed to commit now\n",
      "2024-02-16 08:28:56,420 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1341026145_0004_r_000000_0' to file:/tmp/temp-328978134/tmp1714634746\n",
      "2024-02-16 08:28:56,421 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-16 08:28:56,421 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1341026145_0004_r_000000_0' done.\n",
      "2024-02-16 08:28:56,421 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1341026145_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107673\n",
      "\t\tFILE: Number of bytes written=2497122\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=660078592\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-16 08:28:56,422 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1341026145_0004_r_000000_0\n",
      "2024-02-16 08:28:56,422 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:56,531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1341026145_0004\n",
      "2024-02-16 08:28:56,531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted_data\n",
      "2024-02-16 08:28:56,531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted_data[28,14] C:  R: \n",
      "2024-02-16 08:28:56,532 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 80% complete\n",
      "2024-02-16 08:28:56,533 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,534 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,535 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,539 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-16 08:28:56,539 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-16 08:28:56,540 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-16 08:28:56,540 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-16 08:28:56,541 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-16 08:28:56,550 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-16 08:28:56,552 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,557 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-16 08:28:56,560 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-16 08:28:56,560 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-16 08:28:56,560 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-16 08:28:56,562 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-16 08:28:56,570 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1645361731_0005\n",
      "2024-02-16 08:28:56,570 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-16 08:28:56,646 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-16 08:28:56,646 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-16 08:28:56,651 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-16 08:28:56,651 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-16 08:28:56,651 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-16 08:28:56,652 [Thread-39] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,652 [Thread-39] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,652 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-16 08:28:56,662 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-16 08:28:56,662 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1645361731_0005_m_000000_0\n",
      "2024-02-16 08:28:56,668 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,668 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,668 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:56,669 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 90\n",
      "Input split[0]:\n",
      "   Length = 90\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-16 08:28:56,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-328978134/tmp1714634746/part-r-00000:0+90\n",
      "2024-02-16 08:28:56,681 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-16 08:28:56,681 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-16 08:28:56,681 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-16 08:28:56,681 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-16 08:28:56,681 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-16 08:28:56,682 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-16 08:28:56,684 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:56,684 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:56,685 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_data[28,14] C:  R: \n",
      "2024-02-16 08:28:56,686 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-16 08:28:56,686 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-16 08:28:56,686 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-16 08:28:56,686 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 90; bufvoid = 104857600\n",
      "2024-02-16 08:28:56,686 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2024-02-16 08:28:56,687 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-16 08:28:56,688 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1645361731_0005_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:56,689 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-16 08:28:56,689 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1645361731_0005_m_000000_0' done.\n",
      "2024-02-16 08:28:56,689 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1645361731_0005_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72108211\n",
      "\t\tFILE: Number of bytes written=3107049\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=90\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=660602880\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-16 08:28:56,690 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1645361731_0005_m_000000_0\n",
      "2024-02-16 08:28:56,690 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-16 08:28:56,690 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-16 08:28:56,691 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1645361731_0005_r_000000_0\n",
      "2024-02-16 08:28:56,696 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,696 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,698 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-16 08:28:56,698 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@388f9432\n",
      "2024-02-16 08:28:56,698 [pool-18-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,699 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-16 08:28:56,700 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1645361731_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-16 08:28:56,702 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#5 about to shuffle output of map attempt_local1645361731_0005_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-02-16 08:28:56,702 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local1645361731_0005_m_000000_0\n",
      "2024-02-16 08:28:56,702 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-02-16 08:28:56,703 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-16 08:28:56,704 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-16 08:28:56,704 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-16 08:28:56,706 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-16 08:28:56,706 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-16 08:28:56,706 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-16 08:28:56,707 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-02-16 08:28:56,707 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-16 08:28:56,707 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-16 08:28:56,707 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-16 08:28:56,707 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-16 08:28:56,709 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-16 08:28:56,709 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-16 08:28:56,710 [pool-18-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-16 08:28:56,710 [pool-18-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:56,711 [pool-18-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_data[28,14] C:  R: \n",
      "2024-02-16 08:28:56,712 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1645361731_0005_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-16 08:28:56,714 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-16 08:28:56,714 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1645361731_0005_r_000000_0 is allowed to commit now\n",
      "2024-02-16 08:28:56,716 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1645361731_0005_r_000000_0' to file:/tmp/temp-328978134/tmp801998087\n",
      "2024-02-16 08:28:56,717 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-16 08:28:56,717 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1645361731_0005_r_000000_0' done.\n",
      "2024-02-16 08:28:56,717 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1645361731_0005_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72108455\n",
      "\t\tFILE: Number of bytes written=3107257\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=660602880\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-16 08:28:56,717 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1645361731_0005_r_000000_0\n",
      "2024-02-16 08:28:56,717 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-16 08:28:56,846 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1645361731_0005\n",
      "2024-02-16 08:28:56,847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted_data\n",
      "2024-02-16 08:28:56,847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted_data[28,14] C:  R: \n",
      "2024-02-16 08:28:56,849 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,850 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,851 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2024-02-16 08:28:56,859 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.3.1\t0.17.0\troot\t2024-02-16 08:28:44\t2024-02-16 08:28:56\tHASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local1000492054_0001\t3\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tdelayed_flights,flights,grouped_recovery_count,grouped_total_count,recovered_flights,recovery_count,total_count\tMULTI_QUERY,COMBINER\t\n",
      "job_local1341026145_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted_data\tORDER_BY,COMBINER\t\n",
      "job_local1441971638_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted_data\tSAMPLER\t\n",
      "job_local1645361731_0005\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted_data\t\tfile:/tmp/temp-328978134/tmp801998087,\n",
      "job_local760497629_0002\t2\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tmerged_data,percent_recovered\tHASH_JOIN\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/BDA3/notebooks/flights.csv\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 5 records in: \"file:/tmp/temp-328978134/tmp801998087\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 5\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local1000492054_0001\t->\tjob_local760497629_0002,\n",
      "job_local760497629_0002\t->\tjob_local1441971638_0003,\n",
      "job_local1441971638_0003\t->\tjob_local1341026145_0004,\n",
      "job_local1341026145_0004\t->\tjob_local1645361731_0005,\n",
      "job_local1645361731_0005\n",
      "\n",
      "\n",
      "2024-02-16 08:28:56,860 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,861 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,862 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,867 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,869 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,870 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,875 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,877 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,878 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,882 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,883 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,884 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,887 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,889 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,891 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-16 08:28:56,894 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2024-02-16 08:28:56,898 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-16 08:28:56,901 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-16 08:28:56,901 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(UA,0.24507301133462678)\n",
      "(WN,0.23570878543927196)\n",
      "(FL,0.2265728843597696)\n",
      "(DL,0.21578780710414067)\n",
      "(AA,0.20162014676224854)\n",
      "2024-02-16 08:28:56,937 [main] INFO  org.apache.pig.Main - Pig script completed in 14 seconds and 537 milliseconds (14537 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
